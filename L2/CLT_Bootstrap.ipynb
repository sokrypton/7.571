{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sokrypton/7.571/blob/main/L2/CLT_Bootstrap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Central Limit Theorem & Bootstrap\n",
        "\n",
        "**Goals:**\n",
        "1. Understand the Central Limit Theorem (CLT) - a closed-form solution to estimate standard error\n",
        "2. Understand Bootstrap - a computational approach to estimate standard error\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "D2xq25DvRKO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "McnlWUzFDfW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Problem: Comparing Two Populations\n",
        "\n",
        "Imagine you're comparing gene expression between control and treatment groups.\n",
        "\n",
        "You measure samples from each group and calculate the means. But how do you know if the difference is **real** or just **sampling noise**?"
      ],
      "metadata": {
        "id": "S1taCC04RKPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Two populations we want to compare\n",
        "mu_control = 10.0\n",
        "mu_treatment = 12.0\n",
        "sigma = 4.0  # same variability in both\n",
        "\n",
        "# Take samples from each\n",
        "n = 50\n",
        "control_sample = np.random.normal(loc=mu_control, scale=sigma, size=n)\n",
        "treatment_sample = np.random.normal(loc=mu_treatment, scale=sigma, size=n)\n",
        "\n",
        "# Calculate means\n",
        "control_mean = np.mean(control_sample)\n",
        "treatment_mean = np.mean(treatment_sample)\n",
        "\n",
        "print(f\"Control mean:   {control_mean:.2f}\")\n",
        "print(f\"Treatment mean: {treatment_mean:.2f}\")\n",
        "print(f\"Difference:     {treatment_mean - control_mean:.2f}\")\n",
        "print()\n",
        "print(\"But wait... how do we know this difference is real?\")\n",
        "print(\"What if we just got unlucky with our samples?\")"
      ],
      "metadata": {
        "id": "_Y9uETFeRKPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This is why we need Standard Error!\n",
        "\n",
        "**Standard Error (SE)** tells us how much our estimate might vary if we took a different sample.\n",
        "\n",
        "Formula: **SE = s / sqrt(n)**"
      ],
      "metadata": {
        "id": "ceZkD7DMRKPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate SE for each group\n",
        "control_SE = np.std(control_sample) / np.sqrt(n)\n",
        "treatment_SE = np.std(treatment_sample) / np.sqrt(n)\n",
        "\n",
        "print(f\"Control:   {control_mean:.2f} +/- {control_SE:.2f}\")\n",
        "print(f\"Treatment: {treatment_mean:.2f} +/- {treatment_SE:.2f}\")\n",
        "print()\n",
        "print(\"Now we can see how confident we are in each estimate!\")"
      ],
      "metadata": {
        "id": "ma0cj2ggRKPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## But where does this formula come from?\n",
        "\n",
        "**The Central Limit Theorem** tells us that SE = sigma / sqrt(n)\n",
        "\n",
        "Let's prove it!\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "HIbEEjLiRKPE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Central Limit Theorem (CLT)"
      ],
      "metadata": {
        "id": "aFqX0cq8RKPE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normal Distribution"
      ],
      "metadata": {
        "id": "_WPZT2BwApqe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AutSmmlGAdz9"
      },
      "outputs": [],
      "source": [
        "# Define population parameters\n",
        "mu = 2.0      # population mean\n",
        "sigma = 4.0   # population std\n",
        "\n",
        "# Take ONE sample\n",
        "n = 100\n",
        "samples = np.random.normal(loc=mu, scale=sigma, size=n)\n",
        "plt.hist(samples, bins=10)\n",
        "plt.title('One Sample from Normal Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample mean (our estimate of mu)\n",
        "x_hat = np.mean(samples)\n",
        "print(f\"Sample mean: {x_hat:.4f}\")"
      ],
      "metadata": {
        "id": "fAuo_NzDD6ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Estimated standard error using CLT formula: SE = s / sqrt(n)\n",
        "SE = np.std(samples) / np.sqrt(n)\n",
        "print(f\"Standard Error: {SE:.4f}\")"
      ],
      "metadata": {
        "id": "WIrctAoyEQyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's verify CLT by repeating the experiment many times"
      ],
      "metadata": {
        "id": "cybrBDZ-RKPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Repeat the experiment many times\n",
        "num_experiments = 1000\n",
        "sample_means = []\n",
        "\n",
        "for i in range(num_experiments):\n",
        "    samples = np.random.normal(loc=mu, scale=sigma, size=n)\n",
        "    x_hat = np.mean(samples)\n",
        "    sample_means.append(x_hat)\n",
        "\n",
        "sample_means = np.array(sample_means)"
      ],
      "metadata": {
        "id": "JaJHQ71NEZNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the distribution of sample means\n",
        "plt.hist(sample_means, bins=30, edgecolor='white')\n",
        "plt.axvline(mu, color='red', linestyle='--', label=f'mu = {mu}')\n",
        "\n",
        "# Add std lines\n",
        "theoretical_se = sigma / np.sqrt(n)\n",
        "plt.axvline(mu - theoretical_se, color='orange', linestyle='--', label='mu +/- sigma/sqrt(n)')\n",
        "plt.axvline(mu + theoretical_se, color='orange', linestyle='--')\n",
        "\n",
        "plt.xlabel('Sample Mean')\n",
        "plt.title('Distribution of Sample Means')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Take one sample to show s/sqrt(n)\n",
        "one_sample = np.random.normal(loc=mu, scale=sigma, size=n)\n",
        "estimated_se = np.std(one_sample) / np.sqrt(n)\n",
        "\n",
        "print(\"Verifying CLT\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Observed std of sample means:   {np.std(sample_means):.4f}\")\n",
        "print(f\"Theoretical SE (sigma/sqrt(n)): {sigma/np.sqrt(n):.4f}  <- uses true sigma\")\n",
        "print(f\"Estimated SE (s/sqrt(n)):       {estimated_se:.4f}  <- uses sample s\")\n",
        "print()\n",
        "print(\"In real life, we don't know sigma, so we use s/sqrt(n)\")"
      ],
      "metadata": {
        "id": "gix8rQVvFCIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exponential Distribution\n",
        "\n",
        "CLT works for ANY distribution - let's try one that is clearly NOT normal!"
      ],
      "metadata": {
        "id": "Ka_XWkxUSxtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's try a different distribution\n",
        "lam = 0.5\n",
        "n = 100\n",
        "samples = np.random.exponential(scale=1/lam, size=n)\n",
        "plt.hist(samples, bins=10)\n",
        "plt.title('Exponential Distribution (NOT normal!)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iQPr66wXNoVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Repeat the experiment many times\n",
        "num_experiments = 1000\n",
        "sample_means = []\n",
        "\n",
        "for i in range(num_experiments):\n",
        "    samples = np.random.exponential(scale=1/lam, size=n)\n",
        "    sample_means.append(np.mean(samples))\n",
        "\n",
        "sample_means = np.array(sample_means)"
      ],
      "metadata": {
        "id": "iwZqNSIeMjbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For exponential with rate lambda: mu = 1/lambda, sigma = 1/lambda\n",
        "mu = 1/lam\n",
        "sigma = 1/lam\n",
        "\n",
        "# Plot the distribution of sample means\n",
        "plt.hist(sample_means, bins=30, edgecolor='white')\n",
        "plt.axvline(mu, color='red', linestyle='--', label=f'mu = {mu}')\n",
        "\n",
        "# Add std lines\n",
        "theoretical_se = sigma / np.sqrt(n)\n",
        "plt.axvline(mu - theoretical_se, color='orange', linestyle='--', label='mu +/- sigma/sqrt(n)')\n",
        "plt.axvline(mu + theoretical_se, color='orange', linestyle='--')\n",
        "\n",
        "plt.xlabel('Sample Mean')\n",
        "plt.title('Distribution of Sample Means (normal!)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Take one sample to show s/sqrt(n)\n",
        "one_sample = np.random.exponential(scale=1/lam, size=n)\n",
        "estimated_se = np.std(one_sample) / np.sqrt(n)\n",
        "\n",
        "print(\"Verifying CLT\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Observed std of sample means:   {np.std(sample_means):.4f}\")\n",
        "print(f\"Theoretical SE (sigma/sqrt(n)): {sigma/np.sqrt(n):.4f}  <- uses true sigma\")\n",
        "print(f\"Estimated SE (s/sqrt(n)):       {estimated_se:.4f}  <- uses sample s\")\n",
        "print()\n",
        "print(\"In real life, we don't know sigma, so we use s/sqrt(n)\")"
      ],
      "metadata": {
        "id": "pfdqdMXrNwYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## So What Does This Mean?\n",
        "\n",
        "We did 1000 experiments to prove CLT works.\n",
        "\n",
        "**But in real research, you only get ONE sample!**\n",
        "\n",
        "CLT tells us:\n",
        "- We can estimate standard error from just one sample using: `SE = s / sqrt(n)`\n",
        "- This tells us how much to trust our estimate of the mean\n",
        "\n",
        "**But what if we want SE of something other than the mean?**"
      ],
      "metadata": {
        "id": "nJNbWK5gRKPG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Part 2: Bootstrap"
      ],
      "metadata": {
        "id": "F5u-QYokSNSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: The Problem"
      ],
      "metadata": {
        "id": "rozwRBMGRKPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In real life, you only have ONE sample\n",
        "# And you DON'T know the true mu or sigma\n",
        "\n",
        "lam = 0.5  # In real life, you wouldn't know this!\n",
        "n = 100\n",
        "my_sample = np.random.exponential(scale=1/lam, size=n)\n",
        "\n",
        "print(\"In real life, all you have is your sample:\")\n",
        "print(f\"Sample mean: {np.mean(my_sample):.3f}\")\n",
        "print(f\"Sample std:  {np.std(my_sample):.3f}\")\n",
        "print(f\"Sample size: {n}\")"
      ],
      "metadata": {
        "id": "xPXrEnAdQiAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: CLT Approach Works for the Mean"
      ],
      "metadata": {
        "id": "dRUYN_S2RKPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can estimate SE using the CLT formula\n",
        "SE = np.std(my_sample) / np.sqrt(n)\n",
        "print(f\"SE of mean (using formula): {SE:.4f}\")"
      ],
      "metadata": {
        "id": "XI9z_aBEQicn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: But What About Other Statistics?"
      ],
      "metadata": {
        "id": "RJptbqs4RKPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What if we want SE of the median?\n",
        "sample_median = np.median(my_sample)\n",
        "print(f\"Sample median: {sample_median:.3f}\")\n",
        "print(f\"SE of median:  ???\")  # No formula!"
      ],
      "metadata": {
        "id": "sX9Tejc-QsCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: The Bootstrap Idea\n",
        "\n",
        "Key insight: **Your sample is your best estimate of the population.**\n",
        "\n",
        "So... what if we resample FROM our sample?"
      ],
      "metadata": {
        "id": "CJi8lWfuRKPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is called resampling WITH REPLACEMENT\n",
        "resample = np.random.choice(my_sample, size=n, replace=True)\n",
        "\n",
        "print(\"Original sample (first 10):\", my_sample[:10].round(2))\n",
        "print(\"One resample (first 10):   \", resample[:10].round(2))\n",
        "print(\"\\nNotice: some values repeat, some are missing!\")"
      ],
      "metadata": {
        "id": "V9O6mkvRQvxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Do It Many Times"
      ],
      "metadata": {
        "id": "OV2SNsANRKPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resample many times, calculate mean each time\n",
        "num_resamples = 1000\n",
        "bootstrap_means = []\n",
        "\n",
        "for i in range(num_resamples):\n",
        "    resample = np.random.choice(my_sample, size=n, replace=True)\n",
        "    bootstrap_means.append(np.mean(resample))\n",
        "\n",
        "bootstrap_means = np.array(bootstrap_means)"
      ],
      "metadata": {
        "id": "k1-ZJCfSQ5qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: The Bootstrap SE"
      ],
      "metadata": {
        "id": "Tdu4N3vgRKPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The std of bootstrap means = SE of the mean!\n",
        "bootstrap_SE = np.std(bootstrap_means)\n",
        "formula_SE = np.std(my_sample) / np.sqrt(n)\n",
        "\n",
        "print(\"SE of the Mean\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"Bootstrap SE:        {bootstrap_SE:.4f}\")\n",
        "print(f\"Formula SE (s/sqrt(n)): {formula_SE:.4f}\")\n",
        "print(\"\\nThey match! Bootstrap works.\")"
      ],
      "metadata": {
        "id": "xB0avDN3RN02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Visualize It"
      ],
      "metadata": {
        "id": "N7-0kUyJRKPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(bootstrap_means, bins=30, edgecolor='white')\n",
        "plt.axvline(np.mean(my_sample), color='red', linestyle='--', label='Sample mean')\n",
        "plt.xlabel('Bootstrap Sample Mean')\n",
        "plt.title('Bootstrap Distribution of the Mean')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tP2olylJRP_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Now the Magic - SE of the Median!\n",
        "\n",
        "No formula exists, but bootstrap doesn't care!"
      ],
      "metadata": {
        "id": "P-aG220jRKPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bootstrap_medians = []\n",
        "\n",
        "for i in range(num_resamples):\n",
        "    resample = np.random.choice(my_sample, size=n, replace=True)\n",
        "    bootstrap_medians.append(np.median(resample))\n",
        "\n",
        "bootstrap_medians = np.array(bootstrap_medians)\n",
        "\n",
        "print(\"SE of the Median\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"Sample median:  {np.median(my_sample):.4f}\")\n",
        "print(f\"Bootstrap SE:   {np.std(bootstrap_medians):.4f}\")\n",
        "print(\"\\nNo formula needed!\")"
      ],
      "metadata": {
        "id": "qYuAZeC6RW-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 9: Prove Bootstrap Gives Correct SE for Median\n",
        "\n",
        "To verify bootstrap works, let's compare to the \"true\" SE (from many experiments)."
      ],
      "metadata": {
        "id": "MrD9hPCrRKPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Do the real experiment many times (just like we did for CLT)\n",
        "num_experiments = 1000\n",
        "sample_medians = []\n",
        "\n",
        "for i in range(num_experiments):\n",
        "    samples = np.random.exponential(scale=1/lam, size=n)\n",
        "    sample_medians.append(np.median(samples))\n",
        "\n",
        "sample_medians = np.array(sample_medians)\n",
        "true_SE_median = np.std(sample_medians)\n",
        "\n",
        "print(\"Verifying Bootstrap for the Median\")\n",
        "print(\"=\" * 45)\n",
        "print(f\"True SE (from 1000 experiments):  {true_SE_median:.4f}\")\n",
        "print(f\"Bootstrap SE (from ONE sample):   {np.std(bootstrap_medians):.4f}\")\n",
        "print()"
      ],
      "metadata": {
        "id": "_q1hHxogR01a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Summary\n",
        "\n",
        "## Central Limit Theorem (CLT)\n",
        "- **What:** Distribution of sample means approaches normal, regardless of population shape\n",
        "- **Formula:** SE = sigma / sqrt(n)  (estimate with s / sqrt(n))\n",
        "- **Limitation:** Only works for the mean\n",
        "\n",
        "## Bootstrap\n",
        "- **What:** Computational method to estimate SE of ANY statistic\n",
        "- **How:** Resample with replacement -> Calculate statistic -> Repeat many times -> Take std\n",
        "- **Advantage:** Works for mean, median, or any statistic you can compute!\n",
        "\n",
        "| Method | SE Formula | Works For |\n",
        "|--------|------------|----------|\n",
        "| CLT | s / sqrt(n) | Mean only |\n",
        "| Bootstrap | std(bootstrap statistics) | Anything! |"
      ],
      "metadata": {
        "id": "bQTnyBOMRKPM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BONUS: Anscombe's Quartet + Bootstrap\n",
        "\n",
        "**The question:** Four datasets have the same summary statistics... but should we trust them equally?"
      ],
      "metadata": {
        "id": "5ORxc_SWT2p4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "WRLPrXdgT3th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Anscombe's Quartet\n",
        "\n",
        "Four datasets that are statistically identical but visually very different."
      ],
      "metadata": {
        "id": "e56kpA9iT7wV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Anscombe's quartet data\n",
        "anscombe = {\n",
        "    'I': {\n",
        "        'x': np.array([10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5]),\n",
        "        'y': np.array([8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68])\n",
        "    },\n",
        "    'II': {\n",
        "        'x': np.array([10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5]),\n",
        "        'y': np.array([9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74])\n",
        "    },\n",
        "    'III': {\n",
        "        'x': np.array([10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5]),\n",
        "        'y': np.array([7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73])\n",
        "    },\n",
        "    'IV': {\n",
        "        'x': np.array([8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8]),\n",
        "        'y': np.array([6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89])\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "4Of_Xv7nT6Nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## They all have the same statistics!"
      ],
      "metadata": {
        "id": "G5_NAhCGT_50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_correlation(x, y):\n",
        "    \"\"\"Calculate Pearson correlation coefficient\"\"\"\n",
        "    return np.corrcoef(x, y)[0, 1]\n",
        "\n",
        "def calc_slope(x, y):\n",
        "    \"\"\"Calculate slope of linear regression\"\"\"\n",
        "    return np.cov(x, y)[0, 1] / np.var(x)\n",
        "\n",
        "print(\"Summary Statistics for All Four Datasets\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"{'Dataset':<10} {'Mean X':<10} {'Mean Y':<10} {'Correlation':<12} {'Slope'}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for name, data in anscombe.items():\n",
        "    mx = np.mean(data['x'])\n",
        "    my = np.mean(data['y'])\n",
        "    corr = calc_correlation(data['x'], data['y'])\n",
        "    slope = calc_slope(data['x'], data['y'])\n",
        "    print(f\"{name:<10} {mx:<10.2f} {my:<10.2f} {corr:<12.3f} {slope:.3f}\")\n",
        "\n",
        "print(\"\\nThey're all (nearly) identical!\")"
      ],
      "metadata": {
        "id": "CyANFB1-T9Ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## But they look completely different!"
      ],
      "metadata": {
        "id": "049ngBb6T_ft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, (name, data) in enumerate(anscombe.items()):\n",
        "    ax = axes[i]\n",
        "    ax.scatter(data['x'], data['y'], s=60)\n",
        "\n",
        "    # Add regression line\n",
        "    slope = calc_slope(data['x'], data['y'])\n",
        "    intercept = np.mean(data['y']) - slope * np.mean(data['x'])\n",
        "    x_line = np.linspace(3, 20, 100)\n",
        "    ax.plot(x_line, slope * x_line + intercept, 'r--', alpha=0.7)\n",
        "\n",
        "    ax.set_title(f\"Dataset {name}\\nr = {calc_correlation(data['x'], data['y']):.3f}\")\n",
        "    ax.set_xlabel('x')\n",
        "    ax.set_ylabel('y')\n",
        "    ax.set_xlim(3, 20)\n",
        "    ax.set_ylim(3, 14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Same correlation (0.816), but very different relationships!\")"
      ],
      "metadata": {
        "id": "4QqA8cRvUDRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bootstrap: How confident should we be?\n",
        "\n",
        "Let's bootstrap the correlation for each dataset and see how stable it is."
      ],
      "metadata": {
        "id": "rxL21l3nUK4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bootstrap_correlation(x, y, num_resamples=1000):\n",
        "    \"\"\"Bootstrap the correlation coefficient\"\"\"\n",
        "    n = len(x)\n",
        "    bootstrap_corrs = []\n",
        "\n",
        "    for _ in range(num_resamples):\n",
        "        # Resample indices with replacement\n",
        "        idx = np.random.choice(n, size=n, replace=True)\n",
        "        x_resample = x[idx]\n",
        "        y_resample = y[idx]\n",
        "\n",
        "        # Add tiny noise to avoid zero variance issues\n",
        "        x_resample = x_resample + np.random.normal(0, 0.001, size=n)\n",
        "        y_resample = y_resample + np.random.normal(0, 0.001, size=n)\n",
        "\n",
        "        # Calculate correlation on resample\n",
        "        corr = calc_correlation(x_resample, y_resample)\n",
        "        bootstrap_corrs.append(corr)\n",
        "\n",
        "    return np.array(bootstrap_corrs)"
      ],
      "metadata": {
        "id": "uk_XDRd0UEqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bootstrap all four datasets\n",
        "bootstrap_results = {}\n",
        "\n",
        "for name, data in anscombe.items():\n",
        "    bootstrap_results[name] = bootstrap_correlation(data['x'], data['y'])\n",
        "\n",
        "print(\"Bootstrap Results\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"{'Dataset':<10} {'Correlation':<15} {'Bootstrap SE':<15} {'95% CI'}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for name, boot_corrs in bootstrap_results.items():\n",
        "    original_corr = calc_correlation(anscombe[name]['x'], anscombe[name]['y'])\n",
        "    se = np.std(boot_corrs)\n",
        "    ci_low = np.percentile(boot_corrs, 2.5)\n",
        "    ci_high = np.percentile(boot_corrs, 97.5)\n",
        "    print(f\"{name:<10} {original_corr:<15.3f} {se:<15.3f} [{ci_low:.3f}, {ci_high:.3f}]\")"
      ],
      "metadata": {
        "id": "UN1rB-G_UNHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize the bootstrap distributions"
      ],
      "metadata": {
        "id": "uVU2fqSNUTuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, (name, boot_corrs) in enumerate(bootstrap_results.items()):\n",
        "    ax = axes[i]\n",
        "    ax.hist(boot_corrs, bins=30, edgecolor='white', alpha=0.7)\n",
        "\n",
        "    # Add original correlation line\n",
        "    original_corr = calc_correlation(anscombe[name]['x'], anscombe[name]['y'])\n",
        "    ax.axvline(original_corr, color='red', linestyle='--', linewidth=2)\n",
        "\n",
        "    se = np.std(boot_corrs)\n",
        "    ax.set_title(f\"Dataset {name}\\nSE = {se:.3f}\")\n",
        "    ax.set_xlabel('Correlation')\n",
        "    ax.set_xlim(-1.0, 1.1)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jyJPePn4UQ6e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}