{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sokrypton/7.571/blob/main/L2/Anscombe_Bootstrap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Anscombe's Quartet + Bootstrap\n",
        "\n",
        "**The question:** Four datasets have the same summary statistics... but should we trust them equally?"
      ],
      "metadata": {
        "id": "UuR2oclvRAzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "yXlyCVLMRAze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Anscombe's Quartet\n",
        "\n",
        "Four datasets that are statistically identical but visually very different."
      ],
      "metadata": {
        "id": "oRvdbvt5RAze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Anscombe's quartet data\n",
        "anscombe = {\n",
        "    'I': {\n",
        "        'x': np.array([10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5]),\n",
        "        'y': np.array([8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68])\n",
        "    },\n",
        "    'II': {\n",
        "        'x': np.array([10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5]),\n",
        "        'y': np.array([9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74])\n",
        "    },\n",
        "    'III': {\n",
        "        'x': np.array([10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5]),\n",
        "        'y': np.array([7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73])\n",
        "    },\n",
        "    'IV': {\n",
        "        'x': np.array([8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8]),\n",
        "        'y': np.array([6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89])\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "NmtEGIOVRAze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## They all have the same statistics!"
      ],
      "metadata": {
        "id": "1ja_c55ZRAzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_correlation(x, y):\n",
        "    \"\"\"Calculate Pearson correlation coefficient\"\"\"\n",
        "    return np.corrcoef(x, y)[0, 1]\n",
        "\n",
        "def calc_slope(x, y):\n",
        "    \"\"\"Calculate slope of linear regression\"\"\"\n",
        "    return np.cov(x, y)[0, 1] / np.var(x)\n",
        "\n",
        "print(\"Summary Statistics for All Four Datasets\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"{'Dataset':<10} {'Mean X':<10} {'Mean Y':<10} {'Correlation':<12} {'Slope'}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for name, data in anscombe.items():\n",
        "    mx = np.mean(data['x'])\n",
        "    my = np.mean(data['y'])\n",
        "    corr = calc_correlation(data['x'], data['y'])\n",
        "    slope = calc_slope(data['x'], data['y'])\n",
        "    print(f\"{name:<10} {mx:<10.2f} {my:<10.2f} {corr:<12.3f} {slope:.3f}\")\n",
        "\n",
        "print(\"\\nThey're all (nearly) identical!\")"
      ],
      "metadata": {
        "id": "Osf2aFp_RAzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## But they look completely different!"
      ],
      "metadata": {
        "id": "_ma0_29tRAzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, (name, data) in enumerate(anscombe.items()):\n",
        "    ax = axes[i]\n",
        "    ax.scatter(data['x'], data['y'], s=60)\n",
        "\n",
        "    # Add regression line\n",
        "    slope = calc_slope(data['x'], data['y'])\n",
        "    intercept = np.mean(data['y']) - slope * np.mean(data['x'])\n",
        "    x_line = np.linspace(3, 20, 100)\n",
        "    ax.plot(x_line, slope * x_line + intercept, 'r--', alpha=0.7)\n",
        "\n",
        "    ax.set_title(f\"Dataset {name}\\nr = {calc_correlation(data['x'], data['y']):.3f}\")\n",
        "    ax.set_xlabel('x')\n",
        "    ax.set_ylabel('y')\n",
        "    ax.set_xlim(3, 20)\n",
        "    ax.set_ylim(3, 14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Same correlation (0.816), but very different relationships!\")"
      ],
      "metadata": {
        "id": "MrzVQRq-RAzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bootstrap: How confident should we be?\n",
        "\n",
        "Let's bootstrap the correlation for each dataset and see how stable it is."
      ],
      "metadata": {
        "id": "wLZmrzDpRAzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bootstrap_correlation(x, y, num_resamples=1000):\n",
        "    \"\"\"Bootstrap the correlation coefficient\"\"\"\n",
        "    n = len(x)\n",
        "    bootstrap_corrs = []\n",
        "\n",
        "    for _ in range(num_resamples):\n",
        "        # Resample indices with replacement\n",
        "        idx = np.random.choice(n, size=n, replace=True)\n",
        "        x_resample = x[idx]\n",
        "        y_resample = y[idx]\n",
        "\n",
        "        # Add tiny noise to avoid zero variance issues\n",
        "        x_resample = x_resample + np.random.normal(0, 0.001, size=n)\n",
        "        y_resample = y_resample + np.random.normal(0, 0.001, size=n)\n",
        "\n",
        "        # Calculate correlation on resample\n",
        "        corr = calc_correlation(x_resample, y_resample)\n",
        "        bootstrap_corrs.append(corr)\n",
        "\n",
        "    return np.array(bootstrap_corrs)"
      ],
      "metadata": {
        "id": "SSRTKtH_RAzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bootstrap all four datasets\n",
        "bootstrap_results = {}\n",
        "\n",
        "for name, data in anscombe.items():\n",
        "    bootstrap_results[name] = bootstrap_correlation(data['x'], data['y'])\n",
        "\n",
        "print(\"Bootstrap Results\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"{'Dataset':<10} {'Correlation':<15} {'Bootstrap SE':<15} {'95% CI'}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for name, boot_corrs in bootstrap_results.items():\n",
        "    original_corr = calc_correlation(anscombe[name]['x'], anscombe[name]['y'])\n",
        "    se = np.std(boot_corrs)\n",
        "    ci_low = np.percentile(boot_corrs, 2.5)\n",
        "    ci_high = np.percentile(boot_corrs, 97.5)\n",
        "    print(f\"{name:<10} {original_corr:<15.3f} {se:<15.3f} [{ci_low:.3f}, {ci_high:.3f}]\")"
      ],
      "metadata": {
        "id": "KhTv7BC_RAzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize the bootstrap distributions"
      ],
      "metadata": {
        "id": "SXVkfHAYRAzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, (name, boot_corrs) in enumerate(bootstrap_results.items()):\n",
        "    ax = axes[i]\n",
        "    ax.hist(boot_corrs, bins=30, edgecolor='white', alpha=0.7)\n",
        "\n",
        "    # Add original correlation line\n",
        "    original_corr = calc_correlation(anscombe[name]['x'], anscombe[name]['y'])\n",
        "    ax.axvline(original_corr, color='red', linestyle='--', linewidth=2)\n",
        "\n",
        "    se = np.std(boot_corrs)\n",
        "    ax.set_title(f\"Dataset {name}\\nSE = {se:.3f}\")\n",
        "    ax.set_xlabel('Correlation')\n",
        "    ax.set_xlim(-0.2, 1.1)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WDyJpbJVRAzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Lesson\n",
        "\n",
        "All four datasets have the **same correlation (0.816)**.\n",
        "\n",
        "But bootstrap reveals we shouldn't trust them equally!\n",
        "\n",
        "| Dataset | What's happening | Bootstrap SE | Trust the correlation? |\n",
        "|---------|------------------|--------------|------------------------|\n",
        "| I | Real linear relationship | ~0.10 | Yes |\n",
        "| II | Curved, not linear | ~0.12 | Misleading! |\n",
        "| III | One outlier at x=13 | ~0.09 | Mostly |\n",
        "| IV | One point creates all correlation | ~0.47 | **No!** |\n",
        "\n",
        "Dataset IV's 95% CI spans from **negative to positive** correlation!\n",
        "\n",
        "**Bootstrap SE quantifies how stable your estimate is â€” even when point estimates look the same!**"
      ],
      "metadata": {
        "id": "u_z1-l15RAzf"
      }
    }
  ]
}